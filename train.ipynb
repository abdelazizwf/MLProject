{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1e39c855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from warnings import simplefilter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import set_config\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, RobustScaler\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import (\n",
    "    GradientBoostingClassifier, RandomForestClassifier,\n",
    "    BaggingClassifier, AdaBoostClassifier,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, GridSearchCV\n",
    "\n",
    "from util import drop_empty_features, print_metrics\n",
    "\n",
    "\n",
    "set_config(transform_output='pandas')\n",
    "rs = 5\n",
    "\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "637e58da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4e93264c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_label = \"completion_status\"\n",
    "target = data[target_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b113b66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop empty features\n",
    "data = drop_empty_features(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "089bcc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make all text lowercase\n",
    "filt = (data.dtypes == \"object\") | (data.dtypes == \"bool\")\n",
    "data.loc[:, filt] = data.loc[:, filt].applymap(str.lower, na_action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "666d0b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.loc[:, data.columns != target_label],\n",
    "    target, test_size=0.1, random_state=rs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c6b1a6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns = list(X_train.select_dtypes([\"int64\", \"float64\"]).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e343fb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode ordinary data with the ordered categories, then impute\n",
    "\n",
    "ord_columns = [\n",
    "    'RATE_owner_1', 'RATE_ID_FOR_years_in_business',\n",
    "    'RATE_ID_FOR_judgement_lien_percent',\n",
    "    'RATE_ID_FOR_num_negative_days', 'RATE_ID_FOR_num_deposits',\n",
    "    'RATE_ID_FOR_current_position', 'RATE_owner_4'\n",
    "]\n",
    "\n",
    "categories = [\n",
    "    ['a', 'b', 'c', 'r', 'd'],\n",
    "    ['a', 'b', 'c', 'd'],\n",
    "    ['a', 'b', 'c', 'd'],\n",
    "    ['a', 'b', 'c', 'd'],\n",
    "    ['a', 'b', 'c', 'r'],\n",
    "    ['a', 'c', 'd'],\n",
    "    ['a', 'b', 'c', 'r', 'd'],\n",
    "]\n",
    "\n",
    "ord_enc = OrdinalEncoder(\n",
    "    categories=categories,\n",
    "    handle_unknown='use_encoded_value',\n",
    "    unknown_value=-1\n",
    ")\n",
    "\n",
    "knn_imp = KNNImputer(n_neighbors=1)\n",
    "\n",
    "ord_knn_pipeline = Pipeline(\n",
    "    [('ord_enc', ord_enc), ('knn_imp', knn_imp)]\n",
    ")\n",
    "\n",
    "X_train[ord_columns] = ord_knn_pipeline.fit_transform(X_train[ord_columns])\n",
    "\n",
    "X_test[ord_columns] = ord_knn_pipeline.transform(X_test[ord_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a5692b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./saves/objects/ord_pipeline.p\", \"wb\") as f:\n",
    "    pickle.dump(ord_knn_pipeline, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "db8706f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode binary data, then impute\n",
    "\n",
    "bin_columns = [\n",
    "    'funded_last_30', 'RATE_ID_FOR_judgement_lien_amount',\n",
    "    'RATE_ID_FOR_monthly_gross', 'RATE_ID_FOR_average_ledger',\n",
    "    'RATE_ID_FOR_fc_margin', 'RATE_ID_FOR_tax_lien_amount',\n",
    "    'RATE_ID_FOR_tax_lien_percent', 'RATE_ID_FOR_tax_lien_count',\n",
    "]\n",
    "\n",
    "simple_imp = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "bin_enc = OneHotEncoder(\n",
    "    drop='if_binary',\n",
    "    handle_unknown='ignore',\n",
    "    sparse_output=False\n",
    ")\n",
    "\n",
    "simple_bin_pipeline = Pipeline(\n",
    "    [('simple_imp', simple_imp), ('bin_enc', bin_enc)]\n",
    ")\n",
    "\n",
    "X_train[bin_columns] = simple_bin_pipeline.fit_transform(X_train[bin_columns])\n",
    "\n",
    "X_test[bin_columns] = simple_bin_pipeline.transform(X_test[bin_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0e6b3766",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./saves/objects/bin_pipeline.p\", \"wb\") as f:\n",
    "    pickle.dump(simple_bin_pipeline, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0cb73f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode nominal data, then impute\n",
    "\n",
    "oh_columns = [\n",
    "    'location', 'INPUT_VALUE_ID_FOR_industry_type'\n",
    "]\n",
    "\n",
    "simple_imp2 = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "oh_enc = OneHotEncoder(\n",
    "    drop='first',\n",
    "    handle_unknown='ignore',\n",
    "    sparse_output=False\n",
    ")\n",
    "\n",
    "simple_oh_pipeline = Pipeline(\n",
    "    [('simple_imp2', simple_imp2), ('oh_enc', oh_enc)]\n",
    ")\n",
    "\n",
    "oh_data = simple_oh_pipeline.fit_transform(X_train[oh_columns])\n",
    "X_train.drop(columns=oh_columns, inplace=True)\n",
    "X_train = pd.concat([X_train, oh_data], axis=1)\n",
    "\n",
    "oh_data = simple_oh_pipeline.transform(X_test[oh_columns])\n",
    "X_test.drop(columns=oh_columns, inplace=True)\n",
    "X_test = pd.concat([X_test, oh_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c99fc5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./saves/objects/oh_pipeline.p\", \"wb\") as f:\n",
    "    pickle.dump(simple_oh_pipeline, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e109676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute numerical data, then scale\n",
    "\n",
    "knn_imp2 = KNNImputer()\n",
    "\n",
    "robust_scaler = RobustScaler(quantile_range=(0.03, 0.97))\n",
    "\n",
    "knn_robust_pipeline = Pipeline(\n",
    "    [\n",
    "        ('knn_imp2', knn_imp2),\n",
    "        ('robust_scaler', robust_scaler),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train[num_columns] = knn_robust_pipeline.fit_transform(X_train[num_columns])\n",
    "\n",
    "X_test[num_columns] = knn_robust_pipeline.transform(X_test[num_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "06f1518a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./saves/objects/num_pipeline.p\", \"wb\") as f:\n",
    "    pickle.dump(knn_robust_pipeline, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "de54657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./saves/objects/num_columns.p', 'wb') as f:\n",
    "    pickle.dump(num_columns, f)\n",
    "with open('./saves/objects/ord_columns.p', 'wb') as f:\n",
    "    pickle.dump(ord_columns, f)\n",
    "with open('./saves/objects/bin_columns.p', 'wb') as f:\n",
    "    pickle.dump(bin_columns, f)\n",
    "with open('./saves/objects/oh_columns.p', 'wb') as f:\n",
    "    pickle.dump(oh_columns, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ce333e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop univariate column\n",
    "X_train.drop(columns=['RATE_ID_FOR_location'], inplace=True)\n",
    "X_test.drop(columns=['RATE_ID_FOR_location'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "25d66566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Recursive Feature Elimination to choose the optimal features\n",
    "\n",
    "clf = AdaBoostClassifier(random_state=rs)\n",
    "cv = StratifiedKFold(5)\n",
    "\n",
    "rfecv = RFECV(\n",
    "    estimator=clf,\n",
    "    step=1,\n",
    "    cv=cv,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rfecv.fit(X_train, y_train)\n",
    "\n",
    "X_train = X_train.loc[:, rfecv.support_]\n",
    "X_test = X_test.loc[:, rfecv.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9d48771f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./saves/objects/final_columns.p', 'wb') as f:\n",
    "    pickle.dump(list(X_train.columns), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7ae9d802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n",
      "[CV 1/2] END .....max_depth=5, n_estimators=100;, score=0.638 total time=   0.4s\n",
      "[CV 2/2] END .....max_depth=5, n_estimators=100;, score=0.665 total time=   0.4s\n",
      "[CV 1/2] END .....max_depth=5, n_estimators=200;, score=0.636 total time=   0.8s\n",
      "[CV 2/2] END .....max_depth=5, n_estimators=200;, score=0.663 total time=   0.8s\n",
      "[CV 1/2] END .....max_depth=5, n_estimators=300;, score=0.644 total time=   1.1s\n",
      "[CV 2/2] END .....max_depth=5, n_estimators=300;, score=0.668 total time=   1.1s\n",
      "[CV 1/2] END ....max_depth=10, n_estimators=100;, score=0.815 total time=   0.5s\n",
      "[CV 2/2] END ....max_depth=10, n_estimators=100;, score=0.844 total time=   0.5s\n",
      "[CV 1/2] END ....max_depth=10, n_estimators=200;, score=0.822 total time=   0.9s\n",
      "[CV 2/2] END ....max_depth=10, n_estimators=200;, score=0.853 total time=   0.9s\n",
      "[CV 1/2] END ....max_depth=10, n_estimators=300;, score=0.816 total time=   1.3s\n",
      "[CV 2/2] END ....max_depth=10, n_estimators=300;, score=0.857 total time=   1.5s\n",
      "[CV 1/2] END ....max_depth=25, n_estimators=100;, score=0.869 total time=   0.6s\n",
      "[CV 2/2] END ....max_depth=25, n_estimators=100;, score=0.860 total time=   0.5s\n",
      "[CV 1/2] END ....max_depth=25, n_estimators=200;, score=0.867 total time=   1.0s\n",
      "[CV 2/2] END ....max_depth=25, n_estimators=200;, score=0.860 total time=   1.0s\n",
      "[CV 1/2] END ....max_depth=25, n_estimators=300;, score=0.870 total time=   1.5s\n",
      "[CV 2/2] END ....max_depth=25, n_estimators=300;, score=0.860 total time=   1.4s\n",
      "Accuracy: 96.13 %\n",
      "Precision: 97.65 %\n",
      "Recall: 96.26 %\n",
      "F1 score: 96.89 %\n",
      "Confusion matrix:\n",
      "[[52  3  0  0]\n",
      " [ 1 83  0  0]\n",
      " [ 1  2 33  0]\n",
      " [ 0  0  0  6]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RandomForest\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 25],\n",
    "}\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=rs)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=2, verbose=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "rfc = grid_search.best_estimator_\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "print_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "513a5173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save rfc\n",
    "with open(\"./saves/objects/random_forest_model.p\", \"wb\") as f:\n",
    "    pickle.dump(rfc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d6cde6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n",
      "[CV 1/2] END base_estimator__max_depth=5, n_estimators=100;, score=0.853 total time=   1.1s\n",
      "[CV 2/2] END base_estimator__max_depth=5, n_estimators=100;, score=0.876 total time=   1.1s\n",
      "[CV 1/2] END base_estimator__max_depth=5, n_estimators=200;, score=0.870 total time=   2.3s\n",
      "[CV 2/2] END base_estimator__max_depth=5, n_estimators=200;, score=0.881 total time=   2.3s\n",
      "[CV 1/2] END base_estimator__max_depth=5, n_estimators=300;, score=0.872 total time=   3.4s\n",
      "[CV 2/2] END base_estimator__max_depth=5, n_estimators=300;, score=0.887 total time=   3.7s\n",
      "[CV 1/2] END base_estimator__max_depth=10, n_estimators=100;, score=0.886 total time=   1.5s\n",
      "[CV 2/2] END base_estimator__max_depth=10, n_estimators=100;, score=0.892 total time=   1.4s\n",
      "[CV 1/2] END base_estimator__max_depth=10, n_estimators=200;, score=0.888 total time=   2.8s\n",
      "[CV 2/2] END base_estimator__max_depth=10, n_estimators=200;, score=0.896 total time=   2.8s\n",
      "[CV 1/2] END base_estimator__max_depth=10, n_estimators=300;, score=0.893 total time=   4.1s\n",
      "[CV 2/2] END base_estimator__max_depth=10, n_estimators=300;, score=0.903 total time=   4.1s\n",
      "[CV 1/2] END base_estimator__max_depth=25, n_estimators=100;, score=0.833 total time=   0.0s\n",
      "[CV 2/2] END base_estimator__max_depth=25, n_estimators=100;, score=0.794 total time=   0.0s\n",
      "[CV 1/2] END base_estimator__max_depth=25, n_estimators=200;, score=0.833 total time=   0.0s\n",
      "[CV 2/2] END base_estimator__max_depth=25, n_estimators=200;, score=0.794 total time=   0.0s\n",
      "[CV 1/2] END base_estimator__max_depth=25, n_estimators=300;, score=0.833 total time=   0.0s\n",
      "[CV 2/2] END base_estimator__max_depth=25, n_estimators=300;, score=0.794 total time=   0.0s\n",
      "Accuracy: 96.69 %\n",
      "Precision: 98.12 %\n",
      "Recall: 96.55 %\n",
      "F1 score: 97.26 %\n",
      "Confusion matrix:\n",
      "[[52  3  0  0]\n",
      " [ 0 84  0  0]\n",
      " [ 1  2 33  0]\n",
      " [ 0  0  0  6]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#AdaBoostClassifier DecisionTreeClassifier base\n",
    "param_grid = {\n",
    "    'base_estimator__max_depth': [5, 10, 25],\n",
    "    'n_estimators': [100, 200, 300]\n",
    "}\n",
    "\n",
    "# Define the base classifier\n",
    "base_classifier = DecisionTreeClassifier(random_state=rs)\n",
    "\n",
    "# Define the boosting classifier\n",
    "boosting_classifier = AdaBoostClassifier(base_estimator=base_classifier, random_state=rs)\n",
    "\n",
    "# Perform grid search on the boosting classifier\n",
    "grid_search = GridSearchCV(estimator=boosting_classifier, param_grid=param_grid, cv=2, verbose=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best boosting classifier\n",
    "boosting_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions using the best boosting classifier\n",
    "y_pred = boosting_classifier.predict(X_test)\n",
    "\n",
    "print_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7888d0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save boosting_classifier\n",
    "with open(\"./saves/objects/adaboost_model.p\", \"wb\") as f:\n",
    "    pickle.dump(boosting_classifier, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c8d628b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n",
      "[CV 1/2] END base_estimator__max_depth=5, n_estimators=100;, score=0.692 total time=   0.7s\n",
      "[CV 2/2] END base_estimator__max_depth=5, n_estimators=100;, score=0.699 total time=   0.7s\n",
      "[CV 1/2] END base_estimator__max_depth=5, n_estimators=200;, score=0.679 total time=   1.4s\n",
      "[CV 2/2] END base_estimator__max_depth=5, n_estimators=200;, score=0.709 total time=   1.4s\n",
      "[CV 1/2] END base_estimator__max_depth=5, n_estimators=300;, score=0.677 total time=   2.0s\n",
      "[CV 2/2] END base_estimator__max_depth=5, n_estimators=300;, score=0.704 total time=   2.1s\n",
      "[CV 1/2] END base_estimator__max_depth=10, n_estimators=100;, score=0.850 total time=   0.9s\n",
      "[CV 2/2] END base_estimator__max_depth=10, n_estimators=100;, score=0.848 total time=   0.9s\n",
      "[CV 1/2] END base_estimator__max_depth=10, n_estimators=200;, score=0.850 total time=   1.9s\n",
      "[CV 2/2] END base_estimator__max_depth=10, n_estimators=200;, score=0.853 total time=   1.8s\n",
      "[CV 1/2] END base_estimator__max_depth=10, n_estimators=300;, score=0.849 total time=   2.7s\n",
      "[CV 2/2] END base_estimator__max_depth=10, n_estimators=300;, score=0.851 total time=   2.7s\n",
      "[CV 1/2] END base_estimator__max_depth=25, n_estimators=100;, score=0.882 total time=   1.0s\n",
      "[CV 2/2] END base_estimator__max_depth=25, n_estimators=100;, score=0.856 total time=   1.0s\n",
      "[CV 1/2] END base_estimator__max_depth=25, n_estimators=200;, score=0.882 total time=   2.0s\n",
      "[CV 2/2] END base_estimator__max_depth=25, n_estimators=200;, score=0.859 total time=   1.9s\n",
      "[CV 1/2] END base_estimator__max_depth=25, n_estimators=300;, score=0.880 total time=   3.0s\n",
      "[CV 2/2] END base_estimator__max_depth=25, n_estimators=300;, score=0.864 total time=   2.8s\n",
      "Accuracy: 96.13 %\n",
      "Precision: 97.65 %\n",
      "Recall: 96.26 %\n",
      "F1 score: 96.89 %\n",
      "Confusion matrix:\n",
      "[[52  3  0  0]\n",
      " [ 1 83  0  0]\n",
      " [ 1  2 33  0]\n",
      " [ 0  0  0  6]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#BaggingClassifier DecisionTreeClassifier base\n",
    "\n",
    "param_grid = {\n",
    "    'base_estimator__max_depth': [5, 10, 25],\n",
    "    'n_estimators': [100, 200, 300]\n",
    "}\n",
    "\n",
    "# Define the base classifier\n",
    "base_classifier = DecisionTreeClassifier(random_state=rs)\n",
    "\n",
    "# Define the bagging classifier\n",
    "bagging_classifier = BaggingClassifier(base_estimator=base_classifier, n_estimators=100, random_state=rs)\n",
    "\n",
    "# Perform grid search on the bagging classifier\n",
    "grid_search = GridSearchCV(estimator=bagging_classifier, param_grid=param_grid, cv=2, verbose=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best bagging classifier\n",
    "bagging_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions using the best bagging classifier\n",
    "y_pred = bagging_classifier.predict(X_test)\n",
    "\n",
    "print_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "582e91fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save bagging_classifier\n",
    "with open(\"./saves/objects/bagging_model.p\", \"wb\") as f:\n",
    "    pickle.dump(bagging_classifier, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "529a3dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV 1/2] END learning_rate=0.01, n_estimators=100;, score=0.589 total time=   2.0s\n",
      "[CV 2/2] END learning_rate=0.01, n_estimators=100;, score=0.623 total time=   1.9s\n",
      "[CV 1/2] END learning_rate=0.01, n_estimators=200;, score=0.704 total time=   3.9s\n",
      "[CV 2/2] END learning_rate=0.01, n_estimators=200;, score=0.682 total time=   3.8s\n",
      "[CV 1/2] END learning_rate=0.8, n_estimators=100;, score=0.893 total time=   1.8s\n",
      "[CV 2/2] END learning_rate=0.8, n_estimators=100;, score=0.889 total time=   1.9s\n",
      "[CV 1/2] END learning_rate=0.8, n_estimators=200;, score=0.904 total time=   3.4s\n",
      "[CV 2/2] END learning_rate=0.8, n_estimators=200;, score=0.904 total time=   3.4s\n",
      "Accuracy: 98.34 %\n",
      "Precision: 98.97 %\n",
      "Recall: 97.92 %\n",
      "F1 score: 98.39 %\n",
      "Confusion matrix:\n",
      "[[55  0  0  0]\n",
      " [ 0 84  0  0]\n",
      " [ 1  2 33  0]\n",
      " [ 0  0  0  6]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#GradientBoostingClassifier\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.8],\n",
    "    'n_estimators': [100, 200]\n",
    "}\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state=rs)\n",
    "grid_search = GridSearchCV(estimator=gb_clf, param_grid=param_grid, cv=2, verbose=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best bagging classifier\n",
    "gb_clf = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions using the best bagging classifier\n",
    "y_pred = gb_clf.predict(X_test)\n",
    "\n",
    "print_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3ca1636b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save gb_clf\n",
    "with open(\"./saves/objects/gradientboost_model.p\", \"wb\") as f:\n",
    "    pickle.dump(gb_clf, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "136c0311062c06c8aa7ea0fbdf637a7b64e279566b8a1ef5f99cb561c2b449d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
